# I310D-Final-Project

Over the past decade, social media and online engagement has become the center of information sharing for a large portion of the world’s population—as communication rapidly transforms to rely on instantaneous publication of novel events—the internet houses a wide variety of content containing misinformation, especially as it concerns news and current events. With the internet functioning as an information hub, media outlets have adapted and continue to adapt to the increasingly expeditious ways of online communication. Though the instantaneous, far-reaching nature of online publication or posting of news is beneficial for immediate and widespread access, it is easily taken advantage of—media outlets competing in the market for an audience rely on how fast an article can get published; individuals and groups have deliberately weaponized misinformation via online platforms to further specific agendas; even if unintentionally, social media platforms can easily disguise the truth in an era of content consumption—thus, the need for verifiable, truthful data is crucial to society’s relationship with information. 

Focusing on the interactions between humans and the information they consume, we approached this particular issue of misinformation online with two research questions: How can we use existing news article titles to determine whether the content of the article will contain misinformation? How can we train a machine learning model to determine the validity of the content within the news article based on existing “fake news” data sets? With this, we intended to train a machine learning model to detect “fake news” utilizing news articles from existing datasets. 
